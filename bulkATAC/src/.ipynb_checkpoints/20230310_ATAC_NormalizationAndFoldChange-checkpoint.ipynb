{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "020d72a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "import itertools\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as mpatches\n",
    "import matplotlib.ticker as mticker\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "chrom_list = ['chr'+str(i) for i in range(1,23)]\n",
    "chrom_list.append('chrX')\n",
    "plt.rcParams[\"figure.figsize\"] = (6,4)\n",
    "plt.rcParams[\"font.family\"] = \"Arial\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7297df35",
   "metadata": {},
   "source": [
    "# Loading the data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1829b758",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(259036, 43)\n"
     ]
    }
   ],
   "source": [
    "frag_counts = pd.read_csv('../data/ATAC_fragcounts_raw.txt', sep=' ')\n",
    "peak_ids = frag_counts.index\n",
    "parse_range = lambda x: pd.Series([i.split('-')[x] for i in frag_counts.index])\n",
    "chroms = parse_range(0)\n",
    "starts = parse_range(1).astype('int')\n",
    "ends = parse_range(2).astype('int')\n",
    "frag_counts = frag_counts.reset_index(drop=True)\n",
    "\n",
    "frag_counts['F9'] = frag_counts['F5']\n",
    "frag_counts = frag_counts.drop('F5', axis=1)\n",
    "\n",
    "par_cols = ['P'+str(i) for i in range(1,11)]\n",
    "par_cols.append('parent')\n",
    "new_cols = ['par_'+str(i) for i in range(1,11)]\n",
    "new_cols.append('parent')\n",
    "merged_parental = frag_counts[new_cols].sum(axis=1)\n",
    "print(frag_counts.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "55156252",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(230007, 43)\n"
     ]
    }
   ],
   "source": [
    "par_subclones = ['par_' + str(i) for i in range(1,11)]\n",
    "median_pars = frag_counts[par_subclones].median(axis=1)\n",
    "\n",
    "par_cutoff = 8\n",
    "frag_counts_filtered = frag_counts.copy().loc[median_pars>par_cutoff]\n",
    "\n",
    "chroms_filtered = pd.Series(chroms)[median_pars>par_cutoff]\n",
    "starts_filtered = pd.Series(starts)[median_pars>par_cutoff]\n",
    "ends_filtered = pd.Series(ends)[median_pars>par_cutoff]\n",
    "\n",
    "print(frag_counts_filtered.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db4f9b2c",
   "metadata": {},
   "source": [
    "# Copy-number normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "238f71dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadCN(cn_path, sample_key):\n",
    "    sample_dict = {i:j for i,j in zip(sample_key.ID, sample_key.clone)}\n",
    "    cn = 2*pd.read_csv(cn_path, sep='\\t')\n",
    "    cn_samples = [i.split('_')[1] for i in cn.columns]\n",
    "    cn.columns = [sample_dict[i] for i in cn_samples]\n",
    "\n",
    "    return cn\n",
    "\n",
    "\n",
    "def binCN(cn_df, step):\n",
    "    bins_10kb = pd.read_csv('../data/10kb_bins.csv', sep='\\t')\n",
    "    cn_binned = pd.DataFrame()\n",
    "    new_bins = pd.DataFrame()\n",
    "    for chrom in chrom_list:\n",
    "        chrom_df = pd.DataFrame()\n",
    "        chrom_bins = bins_10kb[bins_10kb.Chr==chrom]\n",
    "        chrom_cn = cn_df.copy().iloc[np.where(bins_10kb.Chr==chrom)[0],:]\n",
    "        bins_step = range(0, max(chrom_bins.End), step*10000)\n",
    "        bin_id = np.digitize(chrom_bins.Start, bins_step)\n",
    "        mean_cn = chrom_cn.groupby(bin_id).mean()\n",
    "        chrom_new_bins = pd.DataFrame()\n",
    "        chrom_new_bins['Start'] = pd.Series([bins_step[i-1] for i in np.unique(bin_id)])\n",
    "        chrom_new_bins['End'] = chrom_new_bins['Start'].values+step*10000\n",
    "        chrom_new_bins['Chr'] = chrom\n",
    "        cn_binned = cn_binned.append(mean_cn)\n",
    "        new_bins = new_bins.append(chrom_new_bins)\n",
    "    cn_binned = cn_binned.reset_index(drop=True)\n",
    "    new_bins = new_bins.reset_index(drop=True)\n",
    "        \n",
    "    return cn_binned, new_bins\n",
    "\n",
    "def normalizeCN(frag_df, frag_chroms, frag_starts, cn_df, bins, samples):\n",
    "    frag_df = frag_df.copy()[samples]\n",
    "    cn_df = cn_df.copy()[samples]\n",
    "    frag_cn = pd.DataFrame()\n",
    "    for chrom in chrom_list:\n",
    "        chrom_bins = bins[bins.Chr==chrom]\n",
    "        chrom_cn = cn_df.copy()[bins.Chr==chrom]\n",
    "        chrom_fragments = frag_df[frag_chroms==chrom]\n",
    "        chrom_starts = frag_starts[frag_chroms==chrom]\n",
    "        peak_bins = np.digitize(chrom_starts, chrom_bins.Start)\n",
    "        chrom_cn.index = range(chrom_cn.shape[0])\n",
    "        chrom_cn = chrom_cn.iloc[[i-1 for i in peak_bins],:]\n",
    "        frag_cn = frag_cn.append(chrom_cn)    \n",
    "    frag_cn.index = range(frag_cn.shape[0])\n",
    "    frag_cn.index = frag_df.index\n",
    "    frag_count_norm = 2*frag_df/frag_cn\n",
    "    \n",
    "    return frag_count_norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "a0c15600",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cn_path = '../data/NormalizedReadDepth.txt'\n",
    "sample_key = pd.read_csv('sample_key.txt', sep='\\t')\n",
    "cn_df = loadCN(cn_path, sample_key)\n",
    "cn_df[cn_df<0.5]=np.nan\n",
    "cn_df['parent'] = cn_df['P10']\n",
    "bins_10kb = pd.read_csv('../data/10kb_bins.csv', sep='\\t')\n",
    "cn_binned, bins_250kb = binCN(cn_df, 25)\n",
    "cn_250kb = cn_binned.copy()\n",
    "#Fixing the sample name discrepancies between ATAC and WGS experiments\n",
    "for i in range(1,11):\n",
    "    cn_250kb['F11_'+str(i)] = cn_250kb['1a'+str(i)].values\n",
    "    cn_250kb['F9_'+str(i)] = cn_250kb['2a'+str(i)].values\n",
    "    cn_250kb['par_'+str(i)] = cn_250kb['P'+str(i)].values\n",
    "cn_250kb['parent'] = cn_250kb['par_1']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dda5f44c",
   "metadata": {},
   "source": [
    "# Using quantile normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e3fecf8a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(230007, 43)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##Loading the data\n",
    "frag_counts = pd.read_csv('../data/peakmatrixNORM220815.txt', sep=' ')\n",
    "frag_counts = frag_counts.reset_index(drop=True)\n",
    "\n",
    "frag_counts['F9'] = frag_counts['F5']\n",
    "frag_counts = frag_counts.drop('F5', axis=1)\n",
    "\n",
    "frag_counts_quantile = frag_counts.loc[frag_counts_filtered.index]\n",
    "frag_counts_quantile.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "08eef524",
   "metadata": {},
   "outputs": [],
   "source": [
    "lib_norm = frag_counts_quantile.copy()\n",
    "cn_norm = normalizeCN(lib_norm, chroms_filtered, starts_filtered, cn_250kb, bins_250kb, frag_counts_filtered.columns.tolist())\n",
    "cn_norm.index = peak_ids[cn_norm.index]\n",
    "# cn_norm.fillna('NA').to_csv('ATAC_frag_counts_CN_masked.txt', sep=' ')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "578634b2",
   "metadata": {},
   "source": [
    "# Fold-change calculation after normalization for library size and CN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "864c006e",
   "metadata": {},
   "outputs": [],
   "source": [
    "fc = cn_norm.copy().divide(cn_norm[par_subclones].median(axis=1), axis=0)\n",
    "sample_list = ['par_'+str(i) for i in range(1,11)]\n",
    "sample_list.extend(['F9_'+str(i) for i in range(1,11)])\n",
    "sample_list.extend(['F11_'+str(i) for i in range(1,11)])\n",
    "sample_list.extend(['parent', 'K11', 'F11', 'B4', 'F9', 'N6', 'E5', 'F3', 'O16', 'K2', 'F2', 'E8', 'N11'])\n",
    "fc = fc[sample_list]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
