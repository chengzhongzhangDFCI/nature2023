{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Import required modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\programdata\\anaconda3\\lib\\site-packages\\skimage\\io\\manage_plugins.py:23: UserWarning: Your installed pillow version is < 7.1.0. Several security issues (CVE-2020-11538, CVE-2020-10379, CVE-2020-10994, CVE-2020-10177) have been fixed in pillow 7.1.0 or higher. We recommend to upgrade this library.\n",
      "  from .collection import imread_collection_wrapper\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage import io\n",
    "from skimage import data\n",
    "import skimage\n",
    "from skimage.filters.thresholding import threshold_li,threshold_local,threshold_otsu\n",
    "from skimage.morphology import erosion, dilation, opening, closing, white_tophat, remove_small_objects, ball\n",
    "from skimage.morphology import disk\n",
    "from scipy import ndimage as ndi\n",
    "import sys,os, glob\n",
    "\n",
    "#import skimage.filters.median\n",
    "\n",
    "#import skimage.segmentation as seg\n",
    "#import skimage.filters as filters\n",
    "#import skimage.draw as draw\n",
    "#import skimage.color as color\n",
    "\n",
    "#from skimage.filters.thresholding import _cross_entropy\n",
    "#from skimage.morphology import black_tophat, skeletonize, convex_hull_image\n",
    "\n",
    "\n",
    "#pip install nd2reader_required for nd2 file reading\n",
    "from nd2reader import ND2Reader\n",
    "\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Define common parameters for image loading here:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['D:\\\\Analyzed_CellBio\\\\Stam\\\\211125IF_211121exp_Mdc1ab_45h\\\\cov1_Mdc1-568 H3K9ac-488 PolS5-647\\\\RPE1 atcc noco45h Mdc1-568 H3K9ac-488 PolS5-647_.nd2',\n",
       " 'D:\\\\Analyzed_CellBio\\\\Stam\\\\211125IF_211121exp_Mdc1ab_45h\\\\cov1_Mdc1-568 H3K9ac-488 PolS5-647\\\\RPE1 atcc noco45h Mdc1-568 H3K9ac-488 PolS5-647_001.nd2',\n",
       " 'D:\\\\Analyzed_CellBio\\\\Stam\\\\211125IF_211121exp_Mdc1ab_45h\\\\cov1_Mdc1-568 H3K9ac-488 PolS5-647\\\\RPE1 atcc noco45h Mdc1-568 H3K9ac-488 PolS5-647_002.nd2',\n",
       " 'D:\\\\Analyzed_CellBio\\\\Stam\\\\211125IF_211121exp_Mdc1ab_45h\\\\cov1_Mdc1-568 H3K9ac-488 PolS5-647\\\\RPE1 atcc noco45h Mdc1-568 H3K9ac-488 PolS5-647_003.nd2',\n",
       " 'D:\\\\Analyzed_CellBio\\\\Stam\\\\211125IF_211121exp_Mdc1ab_45h\\\\cov1_Mdc1-568 H3K9ac-488 PolS5-647\\\\RPE1 atcc noco45h Mdc1-568 H3K9ac-488 PolS5-647_004.nd2']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Common parameters for loading the image files of interest\n",
    "\n",
    "# for 4 channels nd2 images: channel index order is 1-2-3-4, which is the order as ch405-ch488-ch560-ch647\n",
    "\n",
    "\n",
    "# analysis done\n",
    "num_of_ch = 4\n",
    "\n",
    "# Replace protein/dna label name in the \"xxx\" below for the indicated channel index (make sure the order is correct)\n",
    "# For example: ch_dict = {\"dna\":1,\"rpa/rpa2\":2,\"mdc1\":3,\"pol2S5\":4} if rpa/rpa2 was used for ch488\n",
    "# Make sure the label name is the same as the factor/dna key used in the line below\n",
    "ch_dict = {\"dna\":1,\"Mdc1\":3,\"H3K9ac\":2,\"Pol2S5\":4}\n",
    "\n",
    "# If use mdc1 as the factor for region segementation\n",
    "# If use dna/dapi as the key channel for nucleus segmentation\n",
    "mdc1_key =  \"Mdc1\"\n",
    "dna_key = 'dna'  # temporary fix since DNA is not good\n",
    "h2ax_key=\"H3K9ac\"\n",
    "pol2_key = 'Pol2S5'\n",
    "\n",
    "# Whether to analyze the sub-area masks defined by the second marker within the first marker (e.g., h2ax within the mdc) \n",
    "analyze_ch_for_2nd_marker_dict = {1:True,2:True,3:True,4:True}\n",
    "\n",
    "# Replace the data directory in the \"\"; * is the final path level where images are located\n",
    "# For example: data_save_folder = r\"F:\\XXX\\AAA\\BBB\\*\"\n",
    "\n",
    "# define well here\n",
    "# candidate wells: 3, 4, 5, 6, 7\n",
    "#well_name = 'well3' # done\n",
    "#well_name = 'well4' #done\n",
    "#well_name = 'well5' #done\n",
    "#well_name = 'well6' #done\n",
    "#well_name = 'well7' #done\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "############################# CHANGE WELL FOR DATA OF INTEREST ABVOE!##########################################\n",
    "\n",
    "\n",
    "############################# CHANGE WELL FOR DATA OF INTEREST BELOW!##########################################\n",
    "data_main_folder = r\"D:\\Analyzed_CellBio\\Stam\\211125IF_211121exp_Mdc1ab_45h\\cov1_Mdc1-568 H3K9ac-488 PolS5-647\\*\"\n",
    "data_output_folder = r\"D:\\Analyzed_CellBio\\Stam\\211125IF_211121exp_Mdc1ab_45h\\cov1_Mdc1-568 H3K9ac-488 PolS5-647\"\n",
    "############################# CHANGE WELL FOR DATA OF INTEREST HERE!##########################################\n",
    "\n",
    "\n",
    "\n",
    "data_input_folder = data_main_folder\n",
    "data_files = [file for file in glob.glob(data_input_folder) if file[-3:]==\"nd2\"]\n",
    "\n",
    "data_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "3\n",
      "2\n",
      "4\n"
     ]
    }
   ],
   "source": [
    "for ch in [ch for ch in ch_dict.values()]:\n",
    "    print (ch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Generate cell annotation dict from annotation file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#debug_cell_info_dict ={'well3_m6T-488 H2AX-568 RNApol647_024.nd2': {'1': [[1180, 990]]}}\n",
    "\n",
    "#cell_info_dict = debug_cell_info_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#del cell_info_dict['well3_m6T-488 H2AX-568 RNApol647_009.nd2']['6']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Adjust other parameters for image analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# analyze all ND file or not\n",
    "# also used as bool setting for adjusting code indendation between different pipelines\n",
    "_analyze_all_nd = True\n",
    "#_analyze_all_nd = True\n",
    "\n",
    "# print progress\n",
    "_verbose = True\n",
    "\n",
    "# bad fovs to exclude (e.g., out of focus nd file) if analyze all nd file\n",
    "# {nd_file_index : [fov_indexes]}\n",
    "if _analyze_all_nd:\n",
    "    #fov_to_exclude_dict = {1:[4,5],5:[2,3]}\n",
    "    fov_to_exclude_dict = {}\n",
    "    \n",
    "    \n",
    "\n",
    "# The pixel size for excluding small 53BP_body;\n",
    "# Replace *300* with other number desired or *0* if do not want to perform 53BP1 body foci exclusion durng analysis\n",
    "# Desired foci exclusion can still be performed post-hoc in the resulting dataframe after analysis\n",
    "small_53BP_size = 100\n",
    "\n",
    "\n",
    "# Other parameteres for image analysis\n",
    "# border pixel removal for h2ax (or other markers within sub-mdc1 area) positive or less-positive area\n",
    "h2ax_border_size_filter = 1\n",
    "\n",
    "# aproximate size for each cell (nuclei)\n",
    "nuclei_filter = 600\n",
    "\n",
    "# for removing tiny nucleoli areas\n",
    "small_nucleoli_dirt = 10\n",
    "\n",
    "# erosion factor for dna segmenation\n",
    "erosion_factor_dna = 5\n",
    "\n",
    "\n",
    "# std ratio for positive mdc or h2ax, etc calling\n",
    "h2ax_std_ratio = 3\n",
    "mdc_std_ratio = 2\n",
    "\n",
    "# if analyze cell of interest based on annotation:\n",
    "# the approx distance radius range between the given center and the segmenated center\n",
    "coord_dist = 100\n",
    "# if if perform image cropping covering the cell of interest or not\n",
    "crop_image =  True\n",
    "raw_image_size = [2048,2048]\n",
    "\n",
    "# if adjust the focal plane using a smaller crop range than the range used for actual analysis (aka cell size)\n",
    "narrow_adjust = True\n",
    "# define the narrowed ratio of the initial crop\n",
    "narrow_ratio = 0.1\n",
    "\n",
    "\n",
    "# if re-adjust the focal plane based on cell of interest\n",
    "adjust_z_for_cell = False\n",
    "\n",
    "\n",
    "# the cropped image size if performing image cropping covering the cell of interest\n",
    "cell_size =400\n",
    "\n",
    "# the percentile for Pol2 to segment the nucleoli area\n",
    "po2_neg_percentile = 10\n",
    "\n",
    "# use DAPI channel to do nuclei segmentation or not\n",
    "use_dna_nuclei = True # shall be good since local dapi in the center is okay\n",
    "\n",
    "# the alternative channel key if using other channel for nuclei segmentation\n",
    "if not use_dna_nuclei:\n",
    "    dna_key = pol2_key\n",
    "    \n",
    "    \n",
    "# specify the region from the whole fov where analysis would be performed\n",
    "search_xylim = [300,1700]  # Note that DNA channel from the data often is not evenly illuminated\n",
    "\n",
    "\n",
    "# if save the cropped raw images or not\n",
    "save_crop_raw_image = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Analyze each fovs and cells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# analyze cells of interest below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Initiate result dataframe to store analysis measurement:\n",
    "measurement_for_all_fov_df = pd.DataFrame()\n",
    "\n",
    "####################################################################################\n",
    "# Loop through each ND data file\n",
    "for data_ind, data in enumerate(data_files[:]):\n",
    "\n",
    "    # data name: usually the experiment name \n",
    "    data_name = data.split('\\\\')[-1]\n",
    "    \n",
    "    #------------------------------------------------------#\n",
    "    # temp fix for the naming error in the anntotation excel\n",
    "    data_name_p1 = data_name.split('PolS5-647')[0]\n",
    "    data_name_p2 = data_name.split('PolS5-647')[-1]\n",
    "    data_name = data_name_p1 + 'RNApol647' + data_name_p2\n",
    "    \n",
    "    # if use annotation, then check if data/exp name is in the annotation dict\n",
    "    if not _analyze_all_nd:\n",
    "        if data_name in cell_info_dict.keys():\n",
    "            if _verbose:\n",
    "                print(f\"-----------------------------------------------------------\")    \n",
    "                print(f\"-- Start analyzing the dataset of {data_name}\")\n",
    "            # load data if ND data exists in the anntation\n",
    "            images = ND2Reader(data)\n",
    "            num_of_planes = images.sizes[\"z\"] # load 'z' info\n",
    "            # multi-fov image\n",
    "            if 'v' in images.sizes.keys():\n",
    "                num_of_fov = images.sizes[\"v\"] # load 'v' info\n",
    "            # set num_of_fov as 1 for single fov image\n",
    "            else:\n",
    "                num_of_fov = 1\n",
    "        \n",
    "            # load fov_of_interest from the preprocessed cell_info_dict\n",
    "            fov_of_interest_str = cell_info_dict[data_name].keys()\n",
    "            fov_of_interest = [(int(_fov_str)-1) for _fov_str in fov_of_interest_str]\n",
    "            #print(fov_of_interest)\n",
    "        else:\n",
    "            fov_of_interest = []\n",
    "        \n",
    "    # load data without using annotation\n",
    "    else:\n",
    "        images = ND2Reader(data)\n",
    "        num_of_planes = images.sizes[\"z\"] # load 'z' info\n",
    "        # multi-fov image\n",
    "        if 'v' in images.sizes.keys():\n",
    "            num_of_fov = images.sizes[\"v\"] # load 'v' info\n",
    "        # set num_of_fov as 1 for single fov image\n",
    "        else:\n",
    "            num_of_fov = 1\n",
    "            \n",
    "        # if exclude bad focal plane that are not focused\n",
    "        fovs_all = list(range(num_of_fov))\n",
    "        if data_ind in fov_to_exclude_dict.keys():\n",
    "            fov_of_interest = [ind for ind in fovs_all if ind not in fov_to_exclude_dict[data_ind]]\n",
    "        else:\n",
    "            fov_of_interest = fovs_all\n",
    "     \n",
    "    \n",
    "###########################################################################################\n",
    "# Loop through each FOV of interest\n",
    "    if _verbose:# for indentation purposes\n",
    "        \n",
    "        for _fov_id in fov_of_interest[:]:                \n",
    "            \n",
    "            # use annotation dict to look for cell of interest\n",
    "            if not _analyze_all_nd:\n",
    "                if _verbose:\n",
    "                    print ('-- Use given annotation dict to find cells.')\n",
    "                cell_coord_list = cell_info_dict[data_name][str(_fov_id+1)] \n",
    "            \n",
    "            # use 3D nuclei segmenation to roughly look for cell of interest\n",
    "            else:\n",
    "                if _verbose:\n",
    "                    print ('-- Generate 3D nuclei segmentation to find cells.')\n",
    "                image_cell_3d = []\n",
    "                for _lyr in range(num_of_planes): # ch index starts from 0\n",
    "                    image_cell = np.array(images.get_frame_2D (v=_fov_id, c= ch_dict[dna_key]-1, z=_lyr))\n",
    "                    image_cell_3d.append(image_cell)\n",
    "                image_cell_3d = np.array(image_cell_3d)\n",
    "                \n",
    "                \n",
    "                if use_dna_nuclei: # use dapi staining \n",
    "                    th_value =  threshold_li (image_cell_3d)\n",
    "                    nuclei_mask_3d = image_cell_3d>th_value\n",
    "   \n",
    "                #------------------------------------------------------#\n",
    "                # current method for alternative dna segmentation \n",
    "                else: # use e.g., Pol2 staining \n",
    "                    th_value =  threshold_otsu  (image_cell_3d)\n",
    "                    nuclei_mask_3d =  (image_cell_3d) >th_value\n",
    "                    \n",
    "                eroded_nuclei_mask_3d = erosion(nuclei_mask_3d, ball(1))\n",
    "                #eroded_nuclei_mask = dilation(eroded_nuclei_mask, disk(erosion_factor_dna))\n",
    "                \n",
    "                eroded_nuclei_mask_3d = ndi.binary_fill_holes(eroded_nuclei_mask_3d)\n",
    "                eroded_nuclei_mask_3d = remove_small_objects(eroded_nuclei_mask_3d, nuclei_filter*num_of_planes/3,\n",
    "                                                          connectivity=1)\n",
    "                \n",
    "                # rough 3d nuclei segmentation to get all valid nuclei of interest\n",
    "                labeled_nuclei_3d, num_of_nuclei_3d = ndi.label(eroded_nuclei_mask_3d)\n",
    "                #print(num_of_nuclei)\n",
    "                # store the coord to prepare for refined analysis\n",
    "                cell_coord_list  = []\n",
    "                for i in range(num_of_nuclei_3d):\n",
    "                    cand_nucleus = labeled_nuclei_3d == i+1\n",
    "                    cand_nucleus[cand_nucleus>0]=1\n",
    "                    cand_nucleus = np.array(cand_nucleus)\n",
    "                    # append the coord for the objects of interest\n",
    "                    region = skimage.measure.regionprops (skimage.measure.label(cand_nucleus))[0]\n",
    "                    # centroid coord as zYX\n",
    "                    if region.centroid[2] >= search_xylim[0] and region.centroid[2] <= search_xylim[1]:\n",
    "                        if region.centroid[1] > search_xylim[0] and region.centroid[1] < search_xylim[1]:\n",
    "                            cell_coord_list.append([int(region.centroid[2]),int(region.centroid[1])])\n",
    "                if _verbose:\n",
    "                    print (f'-- Processing {len(cell_coord_list)} cells from the image {_fov_id+1}.')\n",
    "\n",
    "###########################################################################################                            \n",
    "# Loop through the cell coord list to analyze cells of interest\n",
    "            \n",
    "            for _cell_id, cell_center in enumerate(cell_coord_list[:]):        \n",
    "                # Find the best focal plane using the m6T/mdc (the factor key) channel for the cell of interest  \n",
    "                #image_fl = []\n",
    "                image_std = []\n",
    "                image_3d_for_label = []\n",
    "                \n",
    "                for _lyr in range(num_of_planes): # ch index starts from 0\n",
    "                    image_array_fl = np.array(images.get_frame_2D (v=_fov_id, c= ch_dict[mdc1_key]-1, z=_lyr))                  \n",
    "                    # do cropping if necessary; remember to inver XY\n",
    "                    if crop_image: # current crop size as rough cell size\n",
    "                        crop_y1 = int(max(0,cell_center[1]-cell_size/2))\n",
    "                        crop_y2 = int(min(raw_image_size[1],cell_center[1]+cell_size/2))\n",
    "                        crop_x1 = int(max(0,cell_center[0]-cell_size/2))\n",
    "                        crop_x2 = int(min(raw_image_size[0],cell_center[0]+cell_size/2))\n",
    "                        image_array_fl = image_array_fl[crop_y1:crop_y2,crop_x1:crop_x2]\n",
    "                    # use image signal STD distribution to find the best focal plane for the plane of interest\n",
    "                    _fl=image_array_fl.flatten()\n",
    "                    # if refine by using a slightly smaller crop\n",
    "                    if narrow_adjust:\n",
    "                        _size = image_array_fl.shape\n",
    "                        _fl=image_array_fl[int(_size[0]*narrow_ratio/2):-int(_size[0]*narrow_ratio/2),\n",
    "                                           int(_size[1]*narrow_ratio/2):-int(_size[1]*narrow_ratio/2)].flatten() \n",
    "                    #image_fl.append(_fl)\n",
    "                    image_std.append(np.std(_fl))\n",
    "                    \n",
    "                    #also pend the image for later potential usage (eg. re-adjust focal plane)\n",
    "                    image_3d_for_label.append(image_array_fl)\n",
    "                # find the initial best focal plane            \n",
    "                best_plane_index = np.argmax(np.array(image_std))\n",
    "                if _verbose:\n",
    "                    print(f\"-- Analyzing the cell {_cell_id+1} for the plane {best_plane_index+1} in fov {_fov_id+1}.\")\n",
    "                    \n",
    "                # load the best focal plane (for each cropped area)\n",
    "                ch_img_dict={}\n",
    "                for _index, _ch in enumerate(range(num_of_ch)):\n",
    "                    sel_img = np.array(images.get_frame_2D (v=_fov_id, c= _ch, z=best_plane_index))\n",
    "                    if crop_image: # current crop size as rough cell size\n",
    "                        sel_img = sel_img[crop_y1:crop_y2,crop_x1:crop_x2]\n",
    "                                  \n",
    "                    # Update/Generate the img_dict\n",
    "                    ch_img_dict[str(_index+1)] = sel_img\n",
    "\n",
    "                # RE-Generate the refined 2D nuclei mask for each cell\n",
    "                if use_dna_nuclei:  # use dapi\n",
    "                    th_value =  threshold_li (ch_img_dict[str(ch_dict[dna_key])])\n",
    "                    nuclei_mask = ch_img_dict[str(ch_dict[dna_key])]>th_value\n",
    "                else: # use Pol2 currently\n",
    "                    th_value =  threshold_otsu (ch_img_dict[str(ch_dict[dna_key])])\n",
    "                    nuclei_mask = ch_img_dict[str(ch_dict[dna_key])]>th_value\n",
    "                \n",
    "                eroded_nuclei_mask = erosion(nuclei_mask, disk(erosion_factor_dna))\n",
    "                eroded_nuclei_mask = dilation(eroded_nuclei_mask, disk(erosion_factor_dna))\n",
    "\n",
    "                \n",
    "                eroded_nuclei_mask = ndi.binary_fill_holes(eroded_nuclei_mask)\n",
    "                eroded_nuclei_mask = remove_small_objects(eroded_nuclei_mask, nuclei_filter,connectivity=1)\n",
    "                \n",
    "                if not use_dna_nuclei: # for Pol2 currently\n",
    "                    eroded_nuclei_mask = skimage.filters.median (eroded_nuclei_mask, disk(10))\n",
    "      \n",
    "                # generate the non-cell background\n",
    "                noncell_background = erosion(eroded_nuclei_mask==0,disk(10))\n",
    "        \n",
    "                # if do further erosion and dilation to remove micronuclei #or small blebs\n",
    "                #eroded_nuclei_mask = erosion(eroded_nuclei_mask, disk(erosion_factor_dna))\n",
    "                #eroded_nuclei_mask = dilation(eroded_nuclei_mask, disk(erosion_factor_dna))\n",
    "                # Nuclei segmentation to get all valid nuclei of interest\n",
    "                labeled_nuclei, num_of_nuclei = ndi.label(eroded_nuclei_mask)\n",
    "                \n",
    "##########################################################################################################                \n",
    "                # Find the nuclei of interest to the list for downstream analysis (should typically have only one)\n",
    "                kept_nuclei_info = []\n",
    "                for i in range(num_of_nuclei):\n",
    "                    cand_nucleus = labeled_nuclei == i+1\n",
    "                    cand_nucleus[cand_nucleus>0]=1\n",
    "                    cand_nucleus = np.array(cand_nucleus)\n",
    "                    \n",
    "                    # find the labeled nuclei close enough to the center of the cropped image (with 50 pixel)\n",
    "                    region = skimage.measure.regionprops (skimage.measure.label(cand_nucleus))[0]\n",
    "                    # centroid coord as YX\n",
    "                    if crop_image: # use crop center\n",
    "                        _dist_diff = np.linalg.norm(np.array([region.centroid[1], region.centroid[0]])\n",
    "                                                    - np.array([cell_size/2,cell_size/2]))\n",
    "                        if _dist_diff <= coord_dist:\n",
    "                            kept_nuclei_info.append([cand_nucleus,_dist_diff])\n",
    "                            \n",
    "                    else: # use cell center coord (in terms of the original image)\n",
    "                        _dist_diff = np.linalg.norm(np.array([region.centroid[1], region.centroid[0]]) - \n",
    "                                                    np.array(cell_center))\n",
    "                        if _dist_diff <= coord_dist:\n",
    "                            kept_nuclei_info.append([cand_nucleus,_dist_diff])\n",
    "                            \n",
    "                # Pick the closest segmented objects for analysis\n",
    "                if len(kept_nuclei_info) >0:\n",
    "                    \n",
    "                    _dist_diff_list =[]\n",
    "                    for _object in kept_nuclei_info:\n",
    "                        _dist_diff_list.append(_object[1])\n",
    "                    _dist_diff_list= np.array(_dist_diff_list)\n",
    "                    _closest_object_index = np.argmin(_dist_diff_list)\n",
    "                    \n",
    "#########################################################################################################\n",
    "            # Proceed to cell specific analysis:\n",
    "                    # load mask for the nuclei to measure\n",
    "                    nuclei_to_measure = kept_nuclei_info[_closest_object_index][0]\n",
    "                    # set measurement list\n",
    "                    measurement_list = []      \n",
    "                    # save the xy for the cell picked for the specified cell center\n",
    "                    sel_nuclei_xy = cell_center\n",
    "\n",
    "#########################################################################################################\n",
    "            # Re-adjust the focal plane if necessary:\n",
    "                    # if re-adjust focal plane specifically for the target cell only\n",
    "                    if adjust_z_for_cell:\n",
    "                        image_std_filtered = []\n",
    "                        for _lyr in image_3d_for_label:\n",
    "                            image_3d_for_label_filtered = (_lyr*nuclei_to_measure).flatten()\n",
    "                            image_std_filtered.append(np.std(image_3d_for_label_filtered))\n",
    "                        # find the refined best focal plane            \n",
    "                        best_plane_index = np.argmax(np.array(image_std_filtered))\n",
    "                        # re-load images using the refined focal plane\n",
    "                        if _verbose:\n",
    "                            print (f'-- Re-adjusting the plane as {best_plane_index+1}.')\n",
    "                        ch_img_dict={}\n",
    "                        for _index, _ch in enumerate(range(num_of_ch)):\n",
    "                            sel_img = np.array(images.get_frame_2D (v=_fov_id, c= _ch, z=best_plane_index))\n",
    "                            if crop_image: # current crop size as rough cell size\n",
    "                                sel_img = sel_img[crop_y1:crop_y2,crop_x1:crop_x2]\n",
    "                                  \n",
    "                            # Update/Generate the img_dict\n",
    "                            ch_img_dict[str(_index+1)] = sel_img\n",
    "                            \n",
    "#########################################################################################################\n",
    "            # Start the final mask segmenation for area of interest from here for each nuclei of interest:\n",
    "                    # Set minimal MDC1 foci size\n",
    "                    if small_53BP_size == 0:\n",
    "                        small_53BP_size = 30\n",
    "    ###################################################################\n",
    "                      #save raw images if necessary\n",
    "                    if crop_image:\n",
    "                        if save_crop_raw_image: \n",
    "                            raw_save_path = data_output_folder + os.sep + f'segmentations_{mdc_std_ratio}_{small_53BP_size}_crop_subset_controlled' +  os.sep + \\\n",
    "                            f'{data_name}' +os.sep + f'_Pos_{_fov_id+1}'\n",
    "                            if not os.path.exists(raw_save_path):\n",
    "                                os.makedirs(raw_save_path)\n",
    "                            if _verbose:\n",
    "                                print(f'-- Saving cropped raw images for cell {_cell_id+1} in this fov.')\n",
    "                                \n",
    "                            #raw_savename_list = []\n",
    "                            #raw_image_list = []\n",
    "                            \n",
    "                            for _ch_key in ch_img_dict.keys():\n",
    "                                raw_savename = f'cell_{_cell_id+1}_ch_{int(_ch_key)}_raw.tif'\n",
    "                                #raw_savename_list.append(raw_savename)\n",
    "                                if os.path.exists(raw_save_path+os.sep+raw_savename):\n",
    "                                    os.remove(raw_save_path+os.sep+raw_savename)\n",
    "                                io.imsave(raw_save_path+os.sep+raw_savename,\n",
    "                                          (ch_img_dict[_ch_key]), check_contrast=False)                   \n",
    "\n",
    "    ########################################################################    \n",
    "                    # Get cellular mdc mask \n",
    "                    mdc_intensity = (ch_img_dict[str(ch_dict[mdc1_key])])*nuclei_to_measure\n",
    "                    mdc_intensity_filtered = mdc_intensity[mdc_intensity!=0]\n",
    "                    mdc_positive_th =np.mean(mdc_intensity_filtered) + np.std(mdc_intensity_filtered)*mdc_std_ratio\n",
    "                    mdc_mask = np.logical_and(ch_img_dict[str(ch_dict[mdc1_key])]>mdc_positive_th, nuclei_to_measure)\n",
    "                    \n",
    "                    # Set minimal MDC1 foci size\n",
    "                    #if small_53BP_size == 0:\n",
    "                        #small_53BP_size = 30\n",
    "                    mdc_chr_mask = remove_small_objects(mdc_mask, small_53BP_size,connectivity=1)\n",
    "                    \n",
    "                    # Proceed if the nuclei has a valid MDC-positive foci\n",
    "                    if np.sum(mdc_chr_mask)>=small_53BP_size:\n",
    "                        if _verbose:\n",
    "                            print(f'-- Measuring cell {_cell_id+1} in fov {_fov_id+1}.')\n",
    "\n",
    "                        # Generate masks for H2AX bright foci similarly but within the mdc-chr mask\n",
    "                        h2ax_intensity = ch_img_dict[str(ch_dict[h2ax_key])]*nuclei_to_measure\n",
    "                        h2ax_intensity_filtered = h2ax_intensity[h2ax_intensity!=0]\n",
    "                        h2ax_positive_th = np.mean(h2ax_intensity_filtered) + 3* np.std(h2ax_intensity_filtered)\n",
    "                        h2ax_foci_mask = np.logical_and((ch_img_dict[str(ch_dict[h2ax_key])] > h2ax_positive_th),mdc_chr_mask)\n",
    "            \n",
    "                        # mask for h2ax negative area within the incorporated chr; \n",
    "                        h2ax_negative_inc_chr_mask_rough = np.logical_xor(mdc_chr_mask,h2ax_foci_mask)\n",
    "                        # use both intensity and minus background to define the h2ax-less ('negative') area\n",
    "                        # currently \"negative (or less)\" is anything lower the positive\n",
    "                        h2ax_negative_th = np.mean(h2ax_intensity_filtered) + np.std(h2ax_intensity_filtered)* h2ax_std_ratio\n",
    "                        h2ax_negative_inc_chr_mask = np.logical_and((ch_img_dict[str(ch_dict[h2ax_key])] \n",
    "                                                                     < h2ax_negative_th)\n",
    "                                                                    ,h2ax_negative_inc_chr_mask_rough)\n",
    "                        \n",
    "                        # Generate mask for the nucleoli\n",
    "                        # lower 10% of the Pol2 intensity for defining the nucleolus \n",
    "                        pol2_intensity = ch_img_dict[str(ch_dict[pol2_key])]*nuclei_to_measure\n",
    "                        pol2_intensity_filtered = pol2_intensity[pol2_intensity!=0]\n",
    "                        # use the pre-esitmated pol2 percentile for nucleoli segmenation\n",
    "                        pol2_negative_th = np.percentile(pol2_intensity_filtered,po2_neg_percentile) \n",
    "                        nucleoli_mask = np.logical_and(ch_img_dict[str(ch_dict[pol2_key])]< pol2_negative_th,nuclei_to_measure)\n",
    "                        nucleoli_mask = remove_small_objects(nucleoli_mask, small_nucleoli_dirt,connectivity=1)\n",
    "                        nucleoli_mask = dilation(nucleoli_mask, disk(3))\n",
    "           \n",
    "                        # Generate mask for the rest chr in nuclei by removing the mdc-labeled and nucleolus regions\n",
    "                        all_ctrl_chr_mask = nuclei_to_measure * (mdc_chr_mask == 0) # without nucleoli exclusion\n",
    "                        nucleo_ex_chr_mask = all_ctrl_chr_mask* (nucleoli_mask ==0) # with nucleoli exclusion\n",
    "                    \n",
    "                    \n",
    "                    \n",
    "                        # Generate a subset of the rest chr as randomized contrl\n",
    "                        _random_index= np.random.choice(np.sum(nucleo_ex_chr_mask), 1)\n",
    "                        _random_yx = [np.where(nucleo_ex_chr_mask==1)[0][_random_index],\n",
    "                              np.where(nucleo_ex_chr_mask==1)[1][_random_index]]\n",
    "                        \n",
    "                        _seed_mask = np.zeros(nucleo_ex_chr_mask.shape)\n",
    "                        _seed_mask [_random_yx[0][0],_random_yx[1][0]] = 1\n",
    "                \n",
    "                        _expand_seed = True\n",
    "                        while _expand_seed:\n",
    "                            _seed_mask = dilation(_seed_mask, disk(3))\n",
    "                            #print (f'-- Generate seed mask for cell {_cell_id}')\n",
    "                            _subset_ctrl_chr_mask = _seed_mask * (nucleo_ex_chr_mask == 1) * (mdc_chr_mask == 0)\n",
    "                            if np.sum(_subset_ctrl_chr_mask) >= np.sum(mdc_chr_mask): \n",
    "                                _expand_seed = False \n",
    "                                #print (f'-- Found control mask for cell {_cell_id}')\n",
    "                        _erode_seed = True\n",
    "                        while _erode_seed:\n",
    "                            if np.sum(_subset_ctrl_chr_mask) >= np.sum(mdc_chr_mask) + 100:\n",
    "                                _subset_ctrl_chr_mask = erosion(_subset_ctrl_chr_mask, disk(1))\n",
    "                            else:\n",
    "                                _erode_seed = False\n",
    "                        \n",
    "#########################################################################################################\n",
    "                        # measurement list for each channel for each cell\n",
    "                        measurement_for_each_cell = []\n",
    "                        \n",
    "                        # Add exp name and fov_id and cell_id  [4 here]\n",
    "                        measurement_for_each_cell.append (data_input_folder.split('\\\\')[-2])  # exp name\n",
    "                        measurement_for_each_cell.append (f'{data_name}_Pos{_fov_id+1}')  # FOV name\n",
    "                        measurement_for_each_cell.append (int(_cell_id+1))   # cell id\n",
    "                        measurement_for_each_cell.append ([sel_nuclei_xy, best_plane_index+1])  # cell xy,z\n",
    "                        # Measure and add pixel area for MDC-labeled chromosome, \n",
    "                        # dna_dmaged part, non-damged part, control chromosomes, nucleolus, nucleolous-excluded control chr\n",
    "                        # [7 here]\n",
    "                        measurement_for_each_cell.append (np.sum(mdc_chr_mask))\n",
    "                        measurement_for_each_cell.append (np.sum(h2ax_foci_mask))\n",
    "                        measurement_for_each_cell.append (np.sum(h2ax_negative_inc_chr_mask))\n",
    "                        measurement_for_each_cell.append (np.sum(all_ctrl_chr_mask))\n",
    "                        measurement_for_each_cell.append (np.sum(nucleoli_mask))\n",
    "                        measurement_for_each_cell.append (np.sum(nucleo_ex_chr_mask))\n",
    "                        \n",
    "                        measurement_for_each_cell.append (np.sum(_subset_ctrl_chr_mask))\n",
    "                        \n",
    "                        # Measure background-substracted intensity for each channel\n",
    "                        # measure intensity for each ch in the order of dna, mdc1, h2ax, pol2\n",
    "                        for ch in [ch for ch in ch_dict.values()]:\n",
    "                            ch_to_measure = ch_img_dict[str(ch)]\n",
    "                        \n",
    "                            # Measure ave intensity\n",
    "                            # mdc1\n",
    "                            mdc_chr_ave_intensity = np.mean((ch_to_measure * mdc_chr_mask)[mdc_chr_mask!=0])\n",
    "                            # all ctrl chromosome\n",
    "                            ctrl_chr_ave_intensity = np.mean((ch_to_measure * all_ctrl_chr_mask)[all_ctrl_chr_mask!=0])\n",
    "                            # nucleoli-excluded ctrl chromosome\n",
    "                            nu_ex_ctrl_chr_ave_intensity = np.mean((ch_to_measure * nucleo_ex_chr_mask)\n",
    "                                                                   [nucleo_ex_chr_mask!=0])\n",
    "                            # nucleoli\n",
    "                            nucleolus_ave_intensity = np.mean((ch_to_measure * nucleoli_mask)[nucleoli_mask!=0])\n",
    "                            # non-cell background\n",
    "                            noncell_background_ave_intensity = np.mean((ch_to_measure*noncell_background)\n",
    "                                                                       [noncell_background!=0])\n",
    "                                                          \n",
    "                            # subset ctrl chromosome                             \n",
    "                            subset_ctrl_chr_ave_intensity = np.mean((ch_to_measure * _subset_ctrl_chr_mask)\n",
    "                                                                   [_subset_ctrl_chr_mask!=0])\n",
    "\n",
    "                            # Background subtraction\n",
    "                            mdc_chr_ave_intensity = mdc_chr_ave_intensity - noncell_background_ave_intensity\n",
    "                            ctrl_chr_ave_intensity = ctrl_chr_ave_intensity - noncell_background_ave_intensity\n",
    "                            nu_ex_ctrl_chr_ave_intensity = nu_ex_ctrl_chr_ave_intensity - noncell_background_ave_intensity\n",
    "                            nucleolus_ave_intensity = nucleolus_ave_intensity - noncell_background_ave_intensity\n",
    "                                                          \n",
    "                            subset_ctrl_chr_ave_intensity = subset_ctrl_chr_ave_intensity - noncell_background_ave_intensity\n",
    "                                                          \n",
    "                    \n",
    "                            # Add measurements  [5* 4 ch = 20 here]\n",
    "                            measurement_for_each_cell.append(mdc_chr_ave_intensity)\n",
    "                            measurement_for_each_cell.append(ctrl_chr_ave_intensity)\n",
    "                            measurement_for_each_cell.append(nu_ex_ctrl_chr_ave_intensity)\n",
    "                            measurement_for_each_cell.append(nucleolus_ave_intensity)\n",
    "                                                          \n",
    "                            measurement_for_each_cell.append(subset_ctrl_chr_ave_intensity)\n",
    "                                                          \n",
    "                            \n",
    "                            # h2ax-positive and negative [2* 4 ch = 8 here]\n",
    "                            # measure pol/h2ax for subregions of incorporated chr (damaged vs non-damaged)\n",
    "                            #if ch == ch_dict[h2ax_key] or ch == ch_dict[pol2_key]:\n",
    "                            analyze_ch_for_2nd_marker = analyze_ch_for_2nd_marker_dict[ch]\n",
    "                            if analyze_ch_for_2nd_marker:\n",
    "                                # erosion to get rid of the border between postive and negative area\n",
    "                                # mostly damaged chr 's negative area could be zero and thus not analyzed\n",
    "                                h2ax_foci_mask_eroded = erosion(h2ax_foci_mask, disk(1))\n",
    "                                h2ax_negative_inc_chr_mask_eroded = erosion(h2ax_negative_inc_chr_mask, disk(1))\n",
    "                                \n",
    "                                # h2ax (positive or less-positive) foci \n",
    "                                # has to be 1/5 size of the 'mdc-foci' to be qualified,\n",
    "                                # then to be quantified \n",
    "                                if (np.sum(h2ax_foci_mask) >= np.sum(mdc_chr_mask)/5 and \n",
    "                                    np.sum(h2ax_foci_mask_eroded) >= small_53BP_size/3):\n",
    "                                    h2ax_pos_chr_ave_intensity = np.mean((ch_to_measure * h2ax_foci_mask_eroded)\n",
    "                                                                         [h2ax_foci_mask_eroded!=0])\n",
    "                                    h2ax_pos_chr_ave_intensity = (h2ax_pos_chr_ave_intensity - \n",
    "                                                                  noncell_background_ave_intensity)\n",
    "                                else: # skip empty mask\n",
    "                                    h2ax_pos_chr_ave_intensity = np.nan\n",
    "                            \n",
    "                                if (np.sum(h2ax_negative_inc_chr_mask) >= np.sum(mdc_chr_mask)/5 and \n",
    "                                    np.sum(h2ax_negative_inc_chr_mask_eroded) >= small_53BP_size/3):\n",
    "                                    \n",
    "                                    h2ax_neg_chr_ave_intensity = np.mean((ch_to_measure * h2ax_negative_inc_chr_mask_eroded)\n",
    "                                                                         [h2ax_negative_inc_chr_mask_eroded!=0])\n",
    "                                    h2ax_neg_chr_ave_intensity = h2ax_neg_chr_ave_intensity - noncell_background_ave_intensity\n",
    "                                else:  # skip empty mask\n",
    "                                    h2ax_neg_chr_ave_intensity = np.nan\n",
    "                                # Add measurements\n",
    "                                measurement_for_each_cell.append(h2ax_pos_chr_ave_intensity)\n",
    "                                measurement_for_each_cell.append(h2ax_neg_chr_ave_intensity)\n",
    "                                      \n",
    "################################################################################################################\n",
    "                       # Add measurement columns for each cell to the measurements dataframe for all fovs   \n",
    "                        measurement_for_each_cell_df = pd.DataFrame()\n",
    "                           \n",
    "                        ch_save_list = ['dna', 'Mdc1', 'H3K9ac', 'Pol2S5']\n",
    "\n",
    "                        ch1 = ch_save_list[0]\n",
    "                        ch2 = ch_save_list[1]\n",
    "                        ch3 = ch_save_list[2]\n",
    "                        ch4 = ch_save_list[3]                \n",
    "\n",
    "                        # total of 33 + 5 (for subset control) measurements\n",
    "                        col_names = ['exp_name','position_id','cell_id', 'cell_xyz_coord',  #4 for basic info\n",
    "                   \n",
    "                   'area_incorporated_chr','area_h2ax_within_incorporated_chr','area_less_h2ax_within_incorporated_chr',\n",
    "                   'area_control_chr','area_nucleo-excluded_control_chr','area_nucleolus', 'area_subset_control_ctrl', #7 for masks size\n",
    "                   \n",
    "             f'ave_intensity_incorporated_chr_{ch1}',f'ave_intensity_control_chr_{ch1}',\n",
    "                  f'ave_intensity_nucleo-excluded_control_chr_{ch1}', f'ave_intensity_nucleolus_{ch1}',\n",
    "                                     f'ave_intensity_subset_control_chr_{ch1}',\n",
    "                   f'ave_intensity_h2ax_pos_incorporated_chr_{ch1}',f'ave_intensity_h2ax_less_incorporated_chr_{ch1}',\n",
    "                   \n",
    "                   \n",
    "                   f'ave_intensity_incorporated_chr_{ch2}',f'ave_intensity_control_chr_{ch2}',\n",
    "                  f'ave_intensity_nucleo-excluded_control_chr_{ch2}', f'ave_intensity_nucleolus_{ch2}',\n",
    "                                     f'ave_intensity_subset_control_chr_{ch2}',\n",
    "                   f'ave_intensity_h2ax_pos_incorporated_chr_{ch2}',f'ave_intensity_h2ax_less_incorporated_chr_{ch2}',\n",
    "                   \n",
    "                   \n",
    "                   f'ave_intensity_incorporated_chr_{ch3}',f'ave_intensity_control_chr_{ch3}',\n",
    "                  f'ave_intensity_nucleo-excluded_control_chr_{ch3}', f'ave_intensity_nucleolus_{ch3}',\n",
    "                                     f'ave_intensity_subset_control_chr_{ch3}',\n",
    "                   f'ave_intensity_h2ax_pos_incorporated_chr_{ch3}',f'ave_intensity_h2ax_less_incorporated_chr_{ch3}',\n",
    "                   \n",
    "                   \n",
    "                   f'ave_intensity_incorporated_chr_{ch4}',f'ave_intensity_control_chr_{ch4}',\n",
    "                  f'ave_intensity_nucleo-excluded_control_chr_{ch4}', f'ave_intensity_nucleolus_{ch4}',\n",
    "                                     f'ave_intensity_subset_control_chr_{ch4}',\n",
    "                   f'ave_intensity_h2ax_pos_incorporated_chr_{ch4}',f'ave_intensity_h2ax_less_incorporated_chr_{ch4}',\n",
    "                   ]\n",
    "                        \n",
    "                        \n",
    "                        for _col_name, _measurement in zip(col_names, measurement_for_each_cell):\n",
    "                            measurement_for_each_cell_df[_col_name] = [_measurement]\n",
    "                        \n",
    "                        \n",
    "                        measurement_for_all_fov_df = pd.concat([measurement_for_all_fov_df,measurement_for_each_cell_df])\n",
    "                        \n",
    "################################################################################################################\n",
    "                       # Save mask segmentations for each cell \n",
    "    \n",
    "                        # segmentation mask for each cell\n",
    "                        # Save mask images in the source directory\n",
    "                        mask_save_path = data_output_folder + os.sep + f'segmentations_{mdc_std_ratio}_{small_53BP_size}_crop_subset_controlled' +  os.sep + \\\n",
    "                        f'{data_name}' +os.sep + f'_Pos_{_fov_id+1}'\n",
    "                        if not os.path.exists(mask_save_path):\n",
    "                            os.makedirs(mask_save_path)\n",
    "                        if _verbose:\n",
    "                            print(f'-- Saving masks for cell {_cell_id+1} in this fov.')\n",
    "                        mdc_chr_mask_savename = f'cell_{_cell_id+1}_incoporated_chr.tif'\n",
    "                        h2ax_foci_mask_savename = f'cell_{_cell_id+1}_h2ax_within_incoporated_chr.tif'\n",
    "                        ctrl_chr_mask_savename = f'cell_{_cell_id+1}_nu_excluded_control_chr.tif'\n",
    "                        subset_ctrl_chr_mask_savename = f'cell_{_cell_id+1}_subset_control_chr.tif'\n",
    "                                                          \n",
    "                        \n",
    "                        mask_savename_list = [mdc_chr_mask_savename,h2ax_foci_mask_savename,\n",
    "                                              ctrl_chr_mask_savename, subset_ctrl_chr_mask_savename]\n",
    "                        mask_file_list = [mdc_chr_mask,h2ax_foci_mask,nucleo_ex_chr_mask, _subset_ctrl_chr_mask] \n",
    "                        \n",
    "                        for _name, _file in zip(mask_savename_list,mask_file_list):\n",
    "                            # remove old ones if exist\n",
    "                            if os.path.exists(mask_save_path+os.sep+_name):\n",
    "                                os.remove(mask_save_path+os.sep+_name)\n",
    "                            io.imsave(mask_save_path+os.sep+_name,(skimage.img_as_ubyte(_file)), check_contrast=False)\n",
    "                        \n",
    "                    # MEASURE and ANALYZE done for each CELL above                       \n",
    "#####################################################################################################################\n",
    "                   # Export results for each experiment\n",
    "    \n",
    "_save_results = True\n",
    "\n",
    "if _save_results:\n",
    "\n",
    "\n",
    "    if _verbose:\n",
    "        print(f'-- Saving results for {len(measurement_for_all_fov_df)} cells for this dataset.')\n",
    "                    \n",
    "    # Replace the protein/dna name below as how they are ordered for the channel (ch405, ch488, ch560, ch647)\n",
    "    # For example, ch_save_list = [\"dna\",\"rpa2\",\"mdc1\",\"pol2S5\"] if rpa2 in ch488\n",
    "    #ch_save_list = [\"dna\",\"m6T\",\"H2AX\",\"Pol2Se\"]\n",
    "    \n",
    "\n",
    "    analysis_savename = f'measurement_for_all_fov_background_subtracted_{mdc_std_ratio}_{small_53BP_size}_crop.xlsx'\n",
    "    #analysis_save_path = data_save_folder[:-2] + os.sep + 'analysis' + os.sep + f'{data_name}' \n",
    "    analysis_save_path = data_output_folder + os.sep + 'analysis_subset_controlled' + os.sep #+ well_name\n",
    "    if not os.path.exists(analysis_save_path):\n",
    "        os.makedirs(analysis_save_path)\n",
    "    measurement_for_all_fov_df.to_excel(analysis_save_path+os.sep+analysis_savename)\n",
    "    \n",
    "    if _verbose:\n",
    "        print(f\"++++++++++++++++++++++++++++++++++++++++++++++++++\")                       \n",
    "                        \n",
    "         \n",
    "         "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Post-hoc analysis examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(measurement_for_all_fov_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove the bad cell that has no Pol2 signal\n",
    "analysis_df=measurement_for_all_fov_df[measurement_for_all_fov_df['ave_intensity_control_chr_Pol2S5']>0].copy()\n",
    "\n",
    "len(analysis_df)\n",
    "\n",
    "analysis_df.to_excel(analysis_save_path+os.sep+analysis_savename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove the bad cell that has no Pol2 signal\n",
    "analysis_df=measurement_for_all_fov_df[measurement_for_all_fov_df['ave_intensity_control_chr_Pol2S5']>0].copy()\n",
    "\n",
    "# for total incorporated chr\n",
    "analysis_df['normalized_inc_Pol2S5']=analysis_df['ave_intensity_incorporated_chr_Pol2S5']/analysis_df['ave_intensity_nucleo-excluded_control_chr_Pol2S5']\n",
    "print(analysis_df['normalized_inc_Pol2S5'].mean())\n",
    "\n",
    "\n",
    "# for subset control\n",
    "analysis_df['normalized_subset_control_Pol2S5']=analysis_df['ave_intensity_subset_control_chr_Pol2S5']/analysis_df['ave_intensity_nucleo-excluded_control_chr_Pol2S5']\n",
    "print(analysis_df['normalized_subset_control_Pol2S5'].mean())\n",
    "\n",
    "\n",
    "\n",
    "# get the h2ax-positive area vs h2ax-less (positive) area for the same cell\n",
    "analysis_df['normalized_inc_H3K9ac'] = analysis_df['ave_intensity_incorporated_chr_H3K9ac']/analysis_df['ave_intensity_nucleo-excluded_control_chr_H3K9ac']\n",
    "print(analysis_df['normalized_inc_H3K9ac'].mean())\n",
    "\n",
    "\n",
    "# for subset control\n",
    "analysis_df['normalized_subset_control_H3K9ac']=analysis_df['ave_intensity_subset_control_chr_H3K9ac']/analysis_df['ave_intensity_nucleo-excluded_control_chr_H3K9ac']\n",
    "print(analysis_df['normalized_subset_control_H3K9ac'].mean())\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# get the h2ax-positive area vs h2ax-less (positive) area for the same cell\n",
    "analysis_df['normalized_inc_Mdc1'] = analysis_df['ave_intensity_incorporated_chr_Mdc1']/analysis_df['ave_intensity_nucleo-excluded_control_chr_Mdc1']\n",
    "print(analysis_df['normalized_inc_Mdc1'].mean())\n",
    "\n",
    "\n",
    "# for subset control\n",
    "analysis_df['normalized_subset_control_Mdc1']=analysis_df['ave_intensity_subset_control_chr_Mdc1']/analysis_df['ave_intensity_nucleo-excluded_control_chr_Mdc1']\n",
    "print(analysis_df['normalized_subset_control_Mdc1'].mean())\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# get the h2ax-positive area vs h2ax-less (positive) area for the same cell\n",
    "analysis_df['normalized_inc_dna'] = analysis_df['ave_intensity_incorporated_chr_dna']/analysis_df['ave_intensity_nucleo-excluded_control_chr_dna']\n",
    "print(analysis_df['normalized_inc_dna'].mean())\n",
    "\n",
    "\n",
    "# for subset control\n",
    "analysis_df['normalized_subset_control_dna']=analysis_df['ave_intensity_subset_control_chr_dna']/analysis_df['ave_intensity_nucleo-excluded_control_chr_dna']\n",
    "print(analysis_df['normalized_subset_control_dna'].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for dna\n",
    "\n",
    "# \n",
    "g1 = analysis_df['normalized_inc_dna']\n",
    "g2 = analysis_df['normalized_subset_control_dna']\n",
    "#g3 = no_damaged_chr_df['normalized_inc_Pol2S5']\n",
    "#g4 = analysis_df['normalized_subset_control_Pol2S5']\n",
    "\n",
    "#sp_low = min(len(g1),len(g2),len(g3))\n",
    "#sp_low = min(len(g1),len(g2), len(g3))\n",
    "\n",
    "#g1 = np.random.choice(g1, sp_low)\n",
    "#g2 = np.random.choice(g2, sp_low)\n",
    "#g3 = np.random.choice(g3, sp_low)\n",
    "#g4 = np.random.choice(g4, sp_low)\n",
    "\n",
    "boxplot_pol2= plt.boxplot([g1,g2], meanline = True)\n",
    "\n",
    "\n",
    "vals, xs = [], [] \n",
    "\n",
    "for i, subdf in enumerate([g1,g2]):\n",
    "    #names.append(name)\n",
    "    vals.append(subdf.tolist())\n",
    "    xs.append(np.random.normal(i+1, 0.04, subdf.shape[0]))\n",
    "\n",
    "for x, val in zip(xs, vals):\n",
    "    plt.scatter(x, val,  s = 5, alpha=0.5)\n",
    "\n",
    "from scipy.stats import mannwhitneyu\n",
    "from scipy.stats import kruskal\n",
    "#p4 = kruskal(g1,g2,g3,g4)\n",
    "\n",
    "U1, p1 = mannwhitneyu(g1,g2)\n",
    "\n",
    "print(f\"MW comparision: {p1}\")\n",
    "\n",
    "\n",
    "\n",
    "#print(f\"three samples comparision: {p4}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for mdc1\n",
    "\n",
    "# \n",
    "g1 = analysis_df['normalized_inc_Mdc1']\n",
    "g2 = analysis_df['normalized_subset_control_Mdc1']\n",
    "#g3 = no_damaged_chr_df['normalized_inc_Pol2S5']\n",
    "#g4 = analysis_df['normalized_subset_control_Pol2S5']\n",
    "\n",
    "#sp_low = min(len(g1),len(g2),len(g3))\n",
    "#sp_low = min(len(g1),len(g2), len(g3))\n",
    "\n",
    "#g1 = np.random.choice(g1, sp_low)\n",
    "#g2 = np.random.choice(g2, sp_low)\n",
    "#g3 = np.random.choice(g3, sp_low)\n",
    "#g4 = np.random.choice(g4, sp_low)\n",
    "\n",
    "boxplot_pol2= plt.boxplot([g1,g2], meanline = True)\n",
    "\n",
    "\n",
    "vals, xs = [], [] \n",
    "\n",
    "for i, subdf in enumerate([g1,g2]):\n",
    "    #names.append(name)\n",
    "    vals.append(subdf.tolist())\n",
    "    xs.append(np.random.normal(i+1, 0.04, subdf.shape[0]))\n",
    "\n",
    "for x, val in zip(xs, vals):\n",
    "    plt.scatter(x, val,  s = 5, alpha=0.5)\n",
    "\n",
    "from scipy.stats import mannwhitneyu\n",
    "from scipy.stats import kruskal\n",
    "#p4 = kruskal(g1,g2,g3,g4)\n",
    "\n",
    "U1, p1 = mannwhitneyu(g1,g2)\n",
    "\n",
    "print(f\"MW comparision: {p1}\")\n",
    "\n",
    "\n",
    "\n",
    "#print(f\"three samples comparision: {p4}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For Pol2S5\n",
    "g1 = analysis_df['normalized_inc_Pol2S5']\n",
    "g2 = analysis_df['normalized_subset_control_Pol2S5']\n",
    "#g3 = no_damaged_chr_df['normalized_inc_Pol2S5']\n",
    "#g4 = analysis_df['normalized_subset_control_Pol2S5']\n",
    "\n",
    "#sp_low = min(len(g1),len(g2),len(g3))\n",
    "#sp_low = min(len(g1),len(g2), len(g3))\n",
    "\n",
    "#g1 = np.random.choice(g1, sp_low)\n",
    "#g2 = np.random.choice(g2, sp_low)\n",
    "#g3 = np.random.choice(g3, sp_low)\n",
    "#g4 = np.random.choice(g4, sp_low)\n",
    "\n",
    "boxplot_pol2= plt.boxplot([g1,g2], meanline = True)\n",
    "\n",
    "\n",
    "vals, xs = [], [] \n",
    "\n",
    "for i, subdf in enumerate([g1,g2]):\n",
    "    #names.append(name)\n",
    "    vals.append(subdf.tolist())\n",
    "    xs.append(np.random.normal(i+1, 0.04, subdf.shape[0]))\n",
    "\n",
    "for x, val in zip(xs, vals):\n",
    "    plt.scatter(x, val,  s = 5, alpha=0.5)\n",
    "\n",
    "from scipy.stats import mannwhitneyu\n",
    "from scipy.stats import kruskal\n",
    "#p4 = kruskal(g1,g2,g3,g4)\n",
    "\n",
    "U1, p1 = mannwhitneyu(g1,g2)\n",
    "\n",
    "print(f\"MW comparision: {p1}\")\n",
    "\n",
    "\n",
    "\n",
    "#print(f\"three samples comparision: {p4}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For Pol2S5 norm to dna\n",
    "g1 = analysis_df['normalized_inc_Pol2S5']/analysis_df['normalized_inc_dna']\n",
    "g2 = analysis_df['normalized_subset_control_Pol2S5']/analysis_df['normalized_subset_control_dna']\n",
    "#g3 = no_damaged_chr_df['normalized_inc_Pol2S5']\n",
    "#g4 = analysis_df['normalized_subset_control_Pol2S5']\n",
    "\n",
    "#sp_low = min(len(g1),len(g2),len(g3))\n",
    "#sp_low = min(len(g1),len(g2), len(g3))\n",
    "\n",
    "#g1 = np.random.choice(g1, sp_low)\n",
    "#g2 = np.random.choice(g2, sp_low)\n",
    "#g3 = np.random.choice(g3, sp_low)\n",
    "#g4 = np.random.choice(g4, sp_low)\n",
    "\n",
    "boxplot_pol2= plt.boxplot([g1,g2], meanline = True)\n",
    "\n",
    "\n",
    "vals, xs = [], [] \n",
    "\n",
    "for i, subdf in enumerate([g1,g2]):\n",
    "    #names.append(name)\n",
    "    vals.append(subdf.tolist())\n",
    "    xs.append(np.random.normal(i+1, 0.04, subdf.shape[0]))\n",
    "\n",
    "for x, val in zip(xs, vals):\n",
    "    plt.scatter(x, val,  s = 5, alpha=0.5)\n",
    "\n",
    "from scipy.stats import mannwhitneyu\n",
    "from scipy.stats import kruskal\n",
    "#p4 = kruskal(g1,g2,g3,g4)\n",
    "\n",
    "U1, p1 = mannwhitneyu(g1,g2)\n",
    "\n",
    "print(f\"MW comparision: {p1}\")\n",
    "\n",
    "\n",
    "\n",
    "#print(f\"three samples comparision: {p4}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For H2ax\n",
    "g1 = analysis_df['normalized_inc_H3K27me3']\n",
    "g2 = analysis_df['normalized_subset_control_H3K27me3']\n",
    "#g3 = no_damaged_chr_df['normalized_inc_Pol2S5']\n",
    "#g4 = analysis_df['normalized_subset_control_Pol2S5']\n",
    "\n",
    "#sp_low = min(len(g1),len(g2),len(g3))\n",
    "#sp_low = min(len(g1),len(g2), len(g3))\n",
    "\n",
    "#g1 = np.random.choice(g1, sp_low)\n",
    "#g2 = np.random.choice(g2, sp_low)\n",
    "#g3 = np.random.choice(g3, sp_low)\n",
    "#g4 = np.random.choice(g4, sp_low)\n",
    "\n",
    "boxplot_pol2= plt.boxplot([g1,g2], meanline = True)\n",
    "\n",
    "\n",
    "vals, xs = [], [] \n",
    "\n",
    "for i, subdf in enumerate([g1,g2]):\n",
    "    #names.append(name)\n",
    "    vals.append(subdf.tolist())\n",
    "    xs.append(np.random.normal(i+1, 0.04, subdf.shape[0]))\n",
    "\n",
    "for x, val in zip(xs, vals):\n",
    "    plt.scatter(x, val,  s = 5, alpha=0.5)\n",
    "\n",
    "\n",
    "from scipy.stats import kruskal\n",
    "#p4 = kruskal(g1,g2,g3,g4)\n",
    "from scipy.stats import mannwhitneyu\n",
    "U1, p1 = mannwhitneyu(g1,g2)\n",
    "\n",
    "print(f\"MW comparision: {p1}\")\n",
    "\n",
    "\n",
    "\n",
    "#print(f\"three samples comparision: {p4}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For H2ax\n",
    "g1 = analysis_df['normalized_inc_H3K27me3']/analysis_df['normalized_inc_dna']\n",
    "g2 = analysis_df['normalized_subset_control_H3K27me3']/analysis_df['normalized_subset_control_dna']\n",
    "#g3 = no_damaged_chr_df['normalized_inc_Pol2S5']\n",
    "#g4 = analysis_df['normalized_subset_control_Pol2S5']\n",
    "\n",
    "#sp_low = min(len(g1),len(g2),len(g3))\n",
    "#sp_low = min(len(g1),len(g2), len(g3))\n",
    "\n",
    "#g1 = np.random.choice(g1, sp_low)\n",
    "#g2 = np.random.choice(g2, sp_low)\n",
    "#g3 = np.random.choice(g3, sp_low)\n",
    "#g4 = np.random.choice(g4, sp_low)\n",
    "\n",
    "boxplot_pol2= plt.boxplot([g1,g2], meanline = True)\n",
    "\n",
    "\n",
    "vals, xs = [], [] \n",
    "\n",
    "for i, subdf in enumerate([g1,g2]):\n",
    "    #names.append(name)\n",
    "    vals.append(subdf.tolist())\n",
    "    xs.append(np.random.normal(i+1, 0.04, subdf.shape[0]))\n",
    "\n",
    "for x, val in zip(xs, vals):\n",
    "    plt.scatter(x, val,  s = 5, alpha=0.5)\n",
    "\n",
    "\n",
    "from scipy.stats import kruskal\n",
    "#p4 = kruskal(g1,g2,g3,g4)\n",
    "from scipy.stats import mannwhitneyu\n",
    "U1, p1 = mannwhitneyu(g1,g2)\n",
    "\n",
    "print(f\"MW comparision: {p1}\")\n",
    "\n",
    "\n",
    "\n",
    "#print(f\"three samples comparision: {p4}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
