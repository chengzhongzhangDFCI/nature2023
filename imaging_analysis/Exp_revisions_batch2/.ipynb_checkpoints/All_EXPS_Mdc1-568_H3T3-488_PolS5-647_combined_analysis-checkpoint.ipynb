{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Import required modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\programdata\\anaconda3\\lib\\site-packages\\skimage\\io\\manage_plugins.py:23: UserWarning: Your installed pillow version is < 7.1.0. Several security issues (CVE-2020-11538, CVE-2020-10379, CVE-2020-10994, CVE-2020-10177) have been fixed in pillow 7.1.0 or higher. We recommend to upgrade this library.\n",
      "  from .collection import imread_collection_wrapper\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage import io\n",
    "from skimage import data\n",
    "import skimage\n",
    "from skimage.filters.thresholding import threshold_li,threshold_local,threshold_otsu\n",
    "from skimage.morphology import erosion, dilation, opening, closing, white_tophat, remove_small_objects, ball\n",
    "from skimage.morphology import disk\n",
    "from scipy import ndimage as ndi\n",
    "import sys,os, glob\n",
    "\n",
    "#import skimage.filters.median\n",
    "\n",
    "#import skimage.segmentation as seg\n",
    "#import skimage.filters as filters\n",
    "#import skimage.draw as draw\n",
    "#import skimage.color as color\n",
    "\n",
    "#from skimage.filters.thresholding import _cross_entropy\n",
    "#from skimage.morphology import black_tophat, skeletonize, convex_hull_image\n",
    "\n",
    "\n",
    "#pip install nd2reader_required for nd2 file reading\n",
    "from nd2reader import ND2Reader\n",
    "\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Define common parameters for measurement loading here:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The labeled histone mark in the excel\n",
    "\n",
    "h2ax_key = 'H3K27me3'\n",
    "\n",
    "\n",
    "# the actual histone mark analyzed  (to correct the mis-labeling in the raw measurements)\n",
    "actual_h2ax_key = 'H3T3'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Control exps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Batch 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load experiment exp1\n",
    "\n",
    "analysis_fd = r'D:\\Analyzed_CellBio\\Stam\\Revision_exps\\220307IF_220214exp_noco45h_Mdc1_H3T3_H3S10\\cov1_H3T3\\\\analysis_subset_controlled'\n",
    "\n",
    "exp1_df = pd.read_excel(analysis_fd + os.sep + 'measurement_for_all_fov_background_subtracted_2_100_crop.xlsx')\n",
    "\n",
    "oldnames = [_c for _c in exp1_df.columns if h2ax_key in _c]\n",
    "newnames = [_c.replace(h2ax_key,actual_h2ax_key) for _c in oldnames]\n",
    "rename_dict = {_o:_n for _o, _n in zip(oldnames,newnames)}\n",
    "exp1_df = exp1_df.rename(columns=rename_dict)\n",
    "\n",
    "\n",
    "exp1_df['exp_annotation']='220307IF_220214exp'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load experiment exp2\n",
    "\n",
    "analysis_fd = r'D:\\Analyzed_CellBio\\Stam\\Revision_exps\\2203087IF_220216exp_noco45h_Mdc1_H3T3_H3S10\\cov1_H3T3\\analysis_subset_controlled'\n",
    "\n",
    "exp2_df = pd.read_excel(analysis_fd + os.sep + 'measurement_for_all_fov_background_subtracted_2_100_crop.xlsx')\n",
    "\n",
    "oldnames = [_c for _c in exp2_df.columns if h2ax_key in _c]\n",
    "newnames = [_c.replace(h2ax_key,actual_h2ax_key) for _c in oldnames]\n",
    "rename_dict = {_o:_n for _o, _n in zip(oldnames,newnames)}\n",
    "exp2_df = exp2_df.rename(columns=rename_dict)\n",
    "\n",
    "\n",
    "exp2_df['exp_annotation']='2203087IF_220216exp'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Batch 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load experiment exp3\n",
    "\n",
    "analysis_fd = r'D:\\Analyzed_CellBio\\Stam\\Revision_exps_p2\\220613IF_newCovs_H3T3_45h\\220307exp_H3T3_newCov_45h\\analysis_subset_controlled'\n",
    "\n",
    "exp3_df = pd.read_excel(analysis_fd + os.sep + 'measurement_for_all_fov_background_subtracted_2_100_crop.xlsx')\n",
    "\n",
    "exp3_df['exp_annotation']='220613IF_220307exp'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "268"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ctrl_combined_df = pd.concat([exp1_df,exp2_df,exp3_df])\n",
    "\n",
    "len(ctrl_combined_df)\n",
    "\n",
    "\n",
    "#measurement_for_all_fov_df = ctrl_combined_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Unnamed: 0', 'exp_name', 'position_id', 'cell_id', 'cell_xyz_coord',\n",
       "       'area_incorporated_chr', 'area_h2ax_within_incorporated_chr',\n",
       "       'area_less_h2ax_within_incorporated_chr', 'area_control_chr',\n",
       "       'area_nucleo-excluded_control_chr', 'area_nucleolus',\n",
       "       'area_subset_control_ctrl', 'ave_intensity_incorporated_chr_dna',\n",
       "       'ave_intensity_control_chr_dna',\n",
       "       'ave_intensity_nucleo-excluded_control_chr_dna',\n",
       "       'ave_intensity_nucleolus_dna', 'ave_intensity_subset_control_chr_dna',\n",
       "       'ave_intensity_h2ax_pos_incorporated_chr_dna',\n",
       "       'ave_intensity_h2ax_less_incorporated_chr_dna',\n",
       "       'ave_intensity_incorporated_chr_Mdc1', 'ave_intensity_control_chr_Mdc1',\n",
       "       'ave_intensity_nucleo-excluded_control_chr_Mdc1',\n",
       "       'ave_intensity_nucleolus_Mdc1', 'ave_intensity_subset_control_chr_Mdc1',\n",
       "       'ave_intensity_h2ax_pos_incorporated_chr_Mdc1',\n",
       "       'ave_intensity_h2ax_less_incorporated_chr_Mdc1',\n",
       "       'ave_intensity_incorporated_chr_H3T3', 'ave_intensity_control_chr_H3T3',\n",
       "       'ave_intensity_nucleo-excluded_control_chr_H3T3',\n",
       "       'ave_intensity_nucleolus_H3T3', 'ave_intensity_subset_control_chr_H3T3',\n",
       "       'ave_intensity_h2ax_pos_incorporated_chr_H3T3',\n",
       "       'ave_intensity_h2ax_less_incorporated_chr_H3T3',\n",
       "       'ave_intensity_incorporated_chr_Pol2S5',\n",
       "       'ave_intensity_control_chr_Pol2S5',\n",
       "       'ave_intensity_nucleo-excluded_control_chr_Pol2S5',\n",
       "       'ave_intensity_nucleolus_Pol2S5',\n",
       "       'ave_intensity_subset_control_chr_Pol2S5',\n",
       "       'ave_intensity_h2ax_pos_incorporated_chr_Pol2S5',\n",
       "       'ave_intensity_h2ax_less_incorporated_chr_Pol2S5', 'exp_annotation'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ctrl_combined_df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Post-hoc analysis examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#len(measurement_for_all_fov_df)\n",
    "\n",
    "\n",
    "analysis_save_path = r'D:\\Analyzed_CellBio\\Stam\\Revision_exps_p2\\H3S10_and_H3T3_analysis'\n",
    "\n",
    "analysis_savename = 'mdc-568_h3t3_pol2_analyzed.xlsx'\n",
    "\n",
    "if not os.path.exists(analysis_save_path):\n",
    "    os.mkdir(analysis_save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "analyzing experiment group 0.\n",
      "-- There are 268 data-points after filtering.\n",
      "0.8318845161807087\n",
      "1.0235384799168075\n",
      "1.1048937120185875\n",
      "1.02616096566035\n",
      "4.174450928177603\n",
      "1.0014652343186812\n",
      "1.0613965132023457\n",
      "1.0010189270048933\n"
     ]
    }
   ],
   "source": [
    "# Process each datafram\n",
    "\n",
    "out_df_dict = {}\n",
    "exp_name_list = [\"Control\"]\n",
    "\n",
    "for _df_index, _df in enumerate([ctrl_combined_df]):\n",
    "    print(f'analyzing experiment group {_df_index}.')\n",
    "\n",
    "    # remove the bad cell that has no Pol2 signal\n",
    "    analysis_df = _df[_df['ave_intensity_control_chr_Pol2S5']>0].copy()\n",
    "    print (f'-- There are {len(analysis_df)} data-points after filtering.')\n",
    "\n",
    "    # for total incorporated chr\n",
    "    analysis_df['normalized_inc_Pol2S5']=analysis_df['ave_intensity_incorporated_chr_Pol2S5']/analysis_df['ave_intensity_nucleo-excluded_control_chr_Pol2S5']\n",
    "    print(analysis_df['normalized_inc_Pol2S5'].mean())\n",
    "\n",
    "    # for subset control\n",
    "    analysis_df['normalized_subset_control_Pol2S5']=analysis_df['ave_intensity_subset_control_chr_Pol2S5']/analysis_df['ave_intensity_nucleo-excluded_control_chr_Pol2S5']\n",
    "    print(analysis_df['normalized_subset_control_Pol2S5'].mean())\n",
    "\n",
    "    # get the h2ax-positive area vs h2ax-less (positive) area for the same cell\n",
    "    analysis_df[f'normalized_inc_{actual_h2ax_key}'] = analysis_df[f'ave_intensity_incorporated_chr_{actual_h2ax_key}']/analysis_df[f'ave_intensity_nucleo-excluded_control_chr_{actual_h2ax_key}']\n",
    "    print(analysis_df[f'normalized_inc_{actual_h2ax_key}'].mean())\n",
    "\n",
    "    # for subset control\n",
    "    analysis_df[f'normalized_subset_control_{actual_h2ax_key}']=analysis_df[f'ave_intensity_subset_control_chr_{actual_h2ax_key}']/analysis_df[f'ave_intensity_nucleo-excluded_control_chr_{actual_h2ax_key}']\n",
    "    print(analysis_df[f'normalized_subset_control_{actual_h2ax_key}'].mean())\n",
    "\n",
    "    # get the h2ax-positive area vs h2ax-less (positive) area for the same cell\n",
    "    analysis_df['normalized_inc_Mdc1'] = analysis_df['ave_intensity_incorporated_chr_Mdc1']/analysis_df['ave_intensity_nucleo-excluded_control_chr_Mdc1']\n",
    "    print(analysis_df['normalized_inc_Mdc1'].mean())\n",
    "\n",
    "    # for subset control\n",
    "    analysis_df['normalized_subset_control_Mdc1']=analysis_df['ave_intensity_subset_control_chr_Mdc1']/analysis_df['ave_intensity_nucleo-excluded_control_chr_Mdc1']\n",
    "    print(analysis_df['normalized_subset_control_Mdc1'].mean())\n",
    "\n",
    "    # get the h2ax-positive area vs h2ax-less (positive) area for the same cell\n",
    "    analysis_df['normalized_inc_dna'] = analysis_df['ave_intensity_incorporated_chr_dna']/analysis_df['ave_intensity_nucleo-excluded_control_chr_dna']\n",
    "    print(analysis_df['normalized_inc_dna'].mean())\n",
    "\n",
    "    # for subset control\n",
    "    analysis_df['normalized_subset_control_dna']=analysis_df['ave_intensity_subset_control_chr_dna']/analysis_df['ave_intensity_nucleo-excluded_control_chr_dna']\n",
    "    print(analysis_df['normalized_subset_control_dna'].mean())\n",
    "    \n",
    "    # reorder some column\n",
    "    col = analysis_df.pop(\"exp_annotation\")\n",
    "    analysis_df.insert(0, \"exp_annotation\", col)\n",
    "    \n",
    "    out_df_key = exp_name_list[_df_index]\n",
    "    out_df_dict[out_df_key]=analysis_df\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#analysis_savename = 'rpe1_h3k27_pol2_analyzed.xlsx'\n",
    "for _exp_key, _exp_df in out_df_dict.items():\n",
    "    exp_analysis_savename = _exp_key+'_'+analysis_savename\n",
    "    _exp_df.to_excel(os.path.join(analysis_save_path,exp_analysis_savename), index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Size filtering with 300 pixels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- There are 143 data-points after filtering.\n"
     ]
    }
   ],
   "source": [
    "size_th =300\n",
    "analysis_filtered_savename = analysis_savename.split('.xlsx')[0]+ f'_size{size_th}' + '.xlsx'\n",
    "\n",
    "\n",
    "for _exp_key, _exp_df in out_df_dict.items():\n",
    "    \n",
    "    _exp_df= _exp_df[_exp_df['area_incorporated_chr']>size_th].copy()\n",
    "    print (f'-- There are {len(_exp_df)} data-points after filtering.')\n",
    "    exp_analysis_savename = _exp_key+'_'+analysis_filtered_savename\n",
    "    _exp_df.to_excel(os.path.join(analysis_save_path,exp_analysis_savename), index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Postion filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- There are 143 data-points after size filtering.\n",
      "-- There are 124 data-points after position filtering.\n"
     ]
    }
   ],
   "source": [
    "def filter_cell_by_coord (xyz_coord_str, bound1=2048, bound2=0, dist_tp_bound = 600):\n",
    "    \n",
    "    xy_coord_str = xyz_coord_str.split('],')[0].split('[[')[-1]\n",
    "    # note here xy is symetric; otherwise need to check which is x and which is y\n",
    "    x=int(xy_coord_str.split(',')[0])\n",
    "    y=int(xy_coord_str.split(',')[1])\n",
    "    \n",
    "    if abs(x-bound1)>=dist_tp_bound and abs(y-bound1)>=dist_tp_bound:\n",
    "        if abs(x-bound2)>=dist_tp_bound and abs(y-bound2)>=dist_tp_bound:\n",
    "            result= 1\n",
    "        else:\n",
    "            result= 0\n",
    "    else:\n",
    "        result= 0\n",
    "\n",
    "    return result\n",
    "        \n",
    "    \n",
    "analysis_filtered_savename = analysis_savename.split('.xlsx')[0]+ f'_size{size_th}_pos_filtered' + '.xlsx'\n",
    "\n",
    "\n",
    "for _exp_key, _exp_df in out_df_dict.items():    \n",
    "    \n",
    "    # size filtering\n",
    "    _exp_df= _exp_df[_exp_df['area_incorporated_chr']>size_th].copy()\n",
    "    print (f'-- There are {len(_exp_df)} data-points after size filtering.')\n",
    "    # postion filtering\n",
    "    _exp_df['pos_kept']=_exp_df['cell_xyz_coord'].map(lambda x: filter_cell_by_coord(x))\n",
    "    _exp_df=_exp_df[_exp_df['pos_kept']==1].copy()\n",
    "    print (f'-- There are {len(_exp_df)} data-points after position filtering.')\n",
    "    exp_analysis_savename = _exp_key+'_'+analysis_filtered_savename\n",
    "    _exp_df.to_excel(os.path.join(analysis_save_path,exp_analysis_savename), index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for dna\n",
    "\n",
    "# \n",
    "g1 = out_df_dict['Control']['normalized_inc_dna']\n",
    "g2 = out_df_dict['Control']['normalized_subset_control_dna']\n",
    "#g3 = out_df_dict['HDACi']['normalized_inc_dna']\n",
    "#g4 = out_df_dict['HDACi']['normalized_subset_control_dna']\n",
    "\n",
    "#sp_low = min(len(g1),len(g2),len(g3))\n",
    "#sp_low = min(len(g1),len(g2), len(g3))\n",
    "\n",
    "#g1 = np.random.choice(g1, sp_low)\n",
    "#g2 = np.random.choice(g2, sp_low)\n",
    "#g3 = np.random.choice(g3, sp_low)\n",
    "#g4 = np.random.choice(g4, sp_low)\n",
    "args = (g1,g2)\n",
    "boxplot_pol2= plt.boxplot([*args], meanline = True)\n",
    "\n",
    "\n",
    "vals, xs = [], [] \n",
    "\n",
    "for i, subdf in enumerate([*args]):\n",
    "    #names.append(name)\n",
    "    vals.append(subdf.tolist())\n",
    "    xs.append(np.random.normal(i+1, 0.04, subdf.shape[0]))\n",
    "\n",
    "for x, val in zip(xs, vals):\n",
    "    plt.scatter(x, val,  s = 1, alpha=0.3)\n",
    "\n",
    "from scipy.stats import mannwhitneyu\n",
    "from scipy.stats import kruskal\n",
    "#p4 = kruskal(g1,g2,g3,g4)\n",
    "\n",
    "U1, p1 = mannwhitneyu(g1,g2)\n",
    "\n",
    "print(f\"MW comparision: {p1}\")\n",
    "\n",
    "\n",
    "\n",
    "#print(f\"three samples comparision: {p4}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for mdc1\n",
    "\n",
    "g1 = out_df_dict['Control']['normalized_inc_Mdc1']\n",
    "g2 = out_df_dict['Control']['normalized_subset_control_Mdc1']\n",
    "#g3 = out_df_dict['HDACi']['normalized_inc_Mdc1']\n",
    "#g4 = out_df_dict['HDACi']['normalized_subset_control_Mdc1']\n",
    "\n",
    "#sp_low = min(len(g1),len(g2),len(g3))\n",
    "#sp_low = min(len(g1),len(g2), len(g3))\n",
    "\n",
    "#g1 = np.random.choice(g1, sp_low)\n",
    "#g2 = np.random.choice(g2, sp_low)\n",
    "#g3 = np.random.choice(g3, sp_low)\n",
    "#g4 = np.random.choice(g4, sp_low)\n",
    "args = (g1,g2)\n",
    "boxplot_pol2= plt.boxplot([*args], meanline = True)\n",
    "\n",
    "\n",
    "vals, xs = [], [] \n",
    "\n",
    "for i, subdf in enumerate([*args]):\n",
    "    #names.append(name)\n",
    "    vals.append(subdf.tolist())\n",
    "    xs.append(np.random.normal(i+1, 0.04, subdf.shape[0]))\n",
    "\n",
    "for x, val in zip(xs, vals):\n",
    "    plt.scatter(x, val,  s = 1, alpha=0.3)\n",
    "\n",
    "from scipy.stats import mannwhitneyu\n",
    "from scipy.stats import kruskal\n",
    "#p4 = kruskal(g1,g2,g3,g4)\n",
    "\n",
    "U1, p1 = mannwhitneyu(g1,g2)\n",
    "\n",
    "print(f\"MW comparision: {p1}\")\n",
    "\n",
    "\n",
    "\n",
    "#print(f\"three samples comparision: {p4}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For Pol2S5\n",
    "\n",
    "g1 = out_df_dict['Control']['normalized_inc_Pol2S5']\n",
    "g2 = out_df_dict['Control']['normalized_subset_control_Pol2S5']\n",
    "#g3 = out_df_dict['HDACi']['normalized_inc_Pol2S5']\n",
    "#g4 = out_df_dict['HDACi']['normalized_subset_control_Pol2S5']\n",
    "\n",
    "#sp_low = min(len(g1),len(g2),len(g3))\n",
    "#sp_low = min(len(g1),len(g2), len(g3))\n",
    "\n",
    "#g1 = np.random.choice(g1, sp_low)\n",
    "#g2 = np.random.choice(g2, sp_low)\n",
    "#g3 = np.random.choice(g3, sp_low)\n",
    "#g4 = np.random.choice(g4, sp_low)\n",
    "args = (g1,g2)\n",
    "boxplot_pol2= plt.boxplot([*args], meanline = True)\n",
    "\n",
    "\n",
    "vals, xs = [], [] \n",
    "\n",
    "for i, subdf in enumerate([*args]):\n",
    "    #names.append(name)\n",
    "    vals.append(subdf.tolist())\n",
    "    xs.append(np.random.normal(i+1, 0.04, subdf.shape[0]))\n",
    "\n",
    "for x, val in zip(xs, vals):\n",
    "    plt.scatter(x, val,  s = 1, alpha=0.3)\n",
    "\n",
    "from scipy.stats import mannwhitneyu\n",
    "from scipy.stats import kruskal\n",
    "#p4 = kruskal(g1,g2,g3,g4)\n",
    "\n",
    "U1, p1 = mannwhitneyu(g1,g2)\n",
    "\n",
    "print(f\"MW comparision: {p1}\")\n",
    "\n",
    "\n",
    "\n",
    "#print(f\"three samples comparision: {p4}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For Pol2S5 norm to dna\n",
    "\n",
    "g1 = (out_df_dict['Control']['normalized_inc_Pol2S5'])/(out_df_dict['Control']['normalized_inc_dna'])\n",
    "g2 = (out_df_dict['Control']['normalized_subset_control_Pol2S5'])/(out_df_dict['Control']['normalized_subset_control_dna'])\n",
    "#g3 = out_df_dict['HDACi']['normalized_inc_Pol2S5']/(out_df_dict['HDACi']['normalized_inc_dna'])\n",
    "#g4 = out_df_dict['HDACi']['normalized_subset_control_Pol2S5']/(out_df_dict['HDACi']['normalized_subset_control_dna'])\n",
    "\n",
    "#sp_low = min(len(g1),len(g2),len(g3))\n",
    "#sp_low = min(len(g1),len(g2), len(g3))\n",
    "\n",
    "#g1 = np.random.choice(g1, sp_low)\n",
    "#g2 = np.random.choice(g2, sp_low)\n",
    "#g3 = np.random.choice(g3, sp_low)\n",
    "#g4 = np.random.choice(g4, sp_low)\n",
    "args = (g1,g2)\n",
    "boxplot_pol2= plt.boxplot([*args], meanline = True)\n",
    "\n",
    "\n",
    "vals, xs = [], [] \n",
    "\n",
    "for i, subdf in enumerate([*args]):\n",
    "    #names.append(name)\n",
    "    vals.append(subdf.tolist())\n",
    "    xs.append(np.random.normal(i+1, 0.04, subdf.shape[0]))\n",
    "\n",
    "for x, val in zip(xs, vals):\n",
    "    plt.scatter(x, val,  s = 1, alpha=0.3)\n",
    "\n",
    "from scipy.stats import mannwhitneyu\n",
    "from scipy.stats import kruskal\n",
    "#p4 = kruskal(g1,g2,g3,g4)\n",
    "\n",
    "U1, p1 = mannwhitneyu(g1,g2)\n",
    "\n",
    "print(f\"MW comparision: {p1}\")\n",
    "\n",
    "\n",
    "\n",
    "#print(f\"three samples comparision: {p4}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For H2ax-key relevant Ab\n",
    "\n",
    "\n",
    "g1 = (out_df_dict['Control'][f'normalized_inc_{actual_h2ax_key}'])\n",
    "g2 = (out_df_dict['Control'][f'normalized_subset_control_{actual_h2ax_key}'])\n",
    "#g3 = out_df_dict['HDACi'][f'normalized_inc_{actual_h2ax_key}']\n",
    "#g4 = out_df_dict['HDACi'][f'normalized_subset_control_{actual_h2ax_key}']\n",
    "\n",
    "#sp_low = min(len(g1),len(g2),len(g3))\n",
    "#sp_low = min(len(g1),len(g2), len(g3))\n",
    "\n",
    "#g1 = np.random.choice(g1, sp_low)\n",
    "#g2 = np.random.choice(g2, sp_low)\n",
    "#g3 = np.random.choice(g3, sp_low)\n",
    "#g4 = np.random.choice(g4, sp_low)\n",
    "args = (g1,g2)\n",
    "boxplot_pol2= plt.boxplot([*args], meanline = True)\n",
    "\n",
    "\n",
    "vals, xs = [], [] \n",
    "\n",
    "for i, subdf in enumerate([*args]):\n",
    "    #names.append(name)\n",
    "    vals.append(subdf.tolist())\n",
    "    xs.append(np.random.normal(i+1, 0.04, subdf.shape[0]))\n",
    "\n",
    "for x, val in zip(xs, vals):\n",
    "    plt.scatter(x, val,  s = 1, alpha=0.3)\n",
    "\n",
    "from scipy.stats import mannwhitneyu\n",
    "from scipy.stats import kruskal\n",
    "#p4 = kruskal(g1,g2,g3,g4)\n",
    "\n",
    "U1, p1 = mannwhitneyu(g1,g2)\n",
    "\n",
    "print(f\"MW comparision: {p1}\")\n",
    "\n",
    "\n",
    "\n",
    "#print(f\"three samples comparision: {p4}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For H2ax-key relevant Ab\n",
    "\n",
    "\n",
    "g1 = (out_df_dict['Control'][f'normalized_inc_{actual_h2ax_key}'])/(out_df_dict['Control']['normalized_inc_dna'])\n",
    "g2 = (out_df_dict['Control'][f'normalized_subset_control_{actual_h2ax_key}'])/(out_df_dict['Control']['normalized_subset_control_dna'])\n",
    "#g3 = out_df_dict['HDACi'][f'normalized_inc_{actual_h2ax_key}']/(out_df_dict['HDACi']['normalized_inc_dna'])\n",
    "#g4 = out_df_dict['HDACi'][f'normalized_subset_control_{actual_h2ax_key}']/(out_df_dict['HDACi']['normalized_subset_control_dna'])\n",
    "\n",
    "#sp_low = min(len(g1),len(g2),len(g3))\n",
    "#sp_low = min(len(g1),len(g2), len(g3))\n",
    "\n",
    "#g1 = np.random.choice(g1, sp_low)\n",
    "#g2 = np.random.choice(g2, sp_low)\n",
    "#g3 = np.random.choice(g3, sp_low)\n",
    "#g4 = np.random.choice(g4, sp_low)\n",
    "args = (g1,g2)\n",
    "boxplot_pol2= plt.boxplot([*args], meanline = True)\n",
    "\n",
    "\n",
    "vals, xs = [], [] \n",
    "\n",
    "for i, subdf in enumerate([*args]):\n",
    "    #names.append(name)\n",
    "    vals.append(subdf.tolist())\n",
    "    xs.append(np.random.normal(i+1, 0.04, subdf.shape[0]))\n",
    "\n",
    "for x, val in zip(xs, vals):\n",
    "    plt.scatter(x, val,  s = 1, alpha=0.3)\n",
    "\n",
    "from scipy.stats import mannwhitneyu\n",
    "from scipy.stats import kruskal\n",
    "#p4 = kruskal(g1,g2,g3,g4)\n",
    "\n",
    "U1, p1 = mannwhitneyu(g1,g2)\n",
    "\n",
    "print(f\"MW comparision: {p1}\")\n",
    "\n",
    "\n",
    "\n",
    "#print(f\"three samples comparision: {p4}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import stats\n",
    "stats.spearmanr(out_df_dict['Control']['normalized_inc_Pol2S5'], out_df_dict['Control'][f'normalized_inc_{actual_h2ax_key}'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(x= out_df_dict['Control']['normalized_inc_Pol2S5'], y =out_df_dict['Control'][f'normalized_inc_{actual_h2ax_key}'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(x= out_df_dict['HDACi']['normalized_inc_Pol2S5'], y =out_df_dict['HDACi'][f'normalized_inc_{actual_h2ax_key}'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
